# -*- coding: utf-8 -*-
"""system_recommendation_books.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QUe7Vf8Wl4uVgmCXtJFxKNEYvNjWr-Cr

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import difflib
import string
from scipy.stats import zscore
from tqdm import tqdm
from collections import defaultdict

# Untuk Text Preprocessing (akan digunakan di tahap Data Preparation lanjut)
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

# Untuk Modeling (akan digunakan di tahap Modeling)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

from wordcloud import WordCloud, STOPWORDS

nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')
stop_words = set(stopwords.words('english'))

"""# Data Understanding"""

df = pd.read_csv('/content/data_books.csv')
df.head()

"""* Melihat ukuran data"""

# Melihat jumlah baris dan kolom
num_rows, num_cols = df.shape
print(f"\n--- Ukuran Data ---")
print(f"Jumlah baris (entri buku): {num_rows}")
print(f"Jumlah kolom (fitur): {num_cols}")

"""* Melihat tipe data"""

print("\n--- Tipe Data Setiap Kolom ---")
print(df.info())

"""Insight: informasi di atas memberikan beberapa informasi yaitu terdapat 10 kolom (fitur) , 6810 baris (entri buku), dan tipe data dari setiap fitur."""

# Melihat missing value
df.isnull().sum()
print("Jumlah missing values dalam setiap kolom:")
print(df.isnull().sum())

"""Insight:
Setelah dilakukan pengecekan terlihat bahwa terdapat banyak missing value pada beberapa fitur. Oleh karena itu, handling missing value menjadi hal penting yang akan dilakukan pada tahap preparation.
"""

# Melihat dan Handling Data Duplikat
num_duplicates = df.duplicated().sum()
print(f"\nJumlah duplikasi data: {num_duplicates}")

"""Insight: tidak terdapat data duplikasi

## Exploratory Data Analysis (EDA)
"""

# Distribusi Rating menggunakan raw data sebelum handling outlier

plt.figure(figsize=(8, 5))
sns.histplot(df['average_rating'], bins=20, kde=True, color='skyblue')
plt.title('Distribusi Average Rating')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.grid(True)
plt.tight_layout()
plt.show()

"""Insight:
* Distribusi Miring ke Kiri (Left-Skewed): Kotak dan median berada di bagian atas rentang data, dan whisker bawah jauh lebih pendek daripada rentang outlier di bawahnya. Ini menegaskan bahwa distribusi data miring ke kiri, dengan konsentrasi data di nilai-nilai tinggi.
* Kualitas Rata-rata Cukup Tinggi: Median di 4.0 menunjukkan bahwa setengah dari "Average Rating" berada di atau di atas 4.0, menunjukkan kualitas yang umumnya baik.
"""

# BUKU TERPOPULER (berdasarkan rata-rata rating tertinggi dan ulasan terbanyak)
top_rated_books = df[df['ratings_count'] > 50].sort_values(by='average_rating', ascending=False).head(10)
plt.figure(figsize=(10, 5))
sns.barplot(x='average_rating', y='title', data=top_rated_books, palette='coolwarm')
plt.title('10 Buku dengan Rata-Rata Rating Tertinggi (≥ 50 ulasan)')
plt.xlabel('Rating')
plt.ylabel('Judul Buku')
plt.tight_layout()
plt.show()

most_reviewed_books = df.sort_values(by='ratings_count', ascending=False).head(10)
plt.figure(figsize=(10, 5))
sns.barplot(x='ratings_count', y='title', data=most_reviewed_books, palette='flare')
plt.title('10 Buku dengan Jumlah Ulasan Terbanyak')
plt.xlabel('Jumlah Ulasan')
plt.ylabel('Judul Buku')
plt.tight_layout()
plt.show()

"""Insight:
- Buku dengan rating tinggi umumnya memiliki banyak ulasan dan menunjukkan popularitasnya. Buku dengan rating tertinggi berjudul "The Complete Calvin and Hobbes"
- Buku populer dengan jumlah ulasan terbanyak berjudul "Harry Potter and the Sorcerer's Stone (Book 1)
"""

# Frekuensi Penulis dan Genre (Top 10)
top_authors = df['authors'].value_counts().head(10)
plt.figure(figsize=(10, 5))
sns.barplot(x=top_authors.values, y=top_authors.index, palette='viridis')
plt.title('10 Penulis Terpopuler')
plt.xlabel('Jumlah Buku')
plt.ylabel('Penulis')
plt.tight_layout()
plt.show()

top_categories = df['categories'].value_counts().head(10)
plt.figure(figsize=(10, 5))
sns.barplot(x=top_categories.values, y=top_categories.index, palette='magma')
plt.title('10 Genre Terpopuler')
plt.xlabel('Jumlah Buku')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""Insight:
* Daftar 10 penulis terpopuler justru dinobatkan kepada author yang tidak diketahui (Unknown Author).
* Daftar 10 genre terpopuler adalah fiksi dengan banyak pengguna yang menyukai genre fiksi ada sekitar 2500 orang.
"""

# Word cloud dari deskripsi buku
text_corpus = ' '.join(df['description'].dropna().astype(str).values)

wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', width=1000, height=600).generate(text_corpus)

plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud dari Deskripsi Buku')
plt.tight_layout()
plt.show()

"""Insight Word Cloud:
- Word cloud menampilkan kata-kata umum yang sering muncul dalam deskripsi, seperti, 'life', 'one', 'book', 'novel', 'world', 'stroynew', 'work'.
"""

# Menampilkan boxplot untuk masing-masing kolom numerik
numerical_cols = ['average_rating', 'num_pages', 'ratings_count']

plt.figure(figsize=(15, 5))
for i, col in enumerate(numerical_cols):
    plt.subplot(1, 3, i+1)
    sns.boxplot(y=df[col], color='lightblue')
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""Insight: boxplot di atas menunjukkan outliers yang ektrem pada tiga fitur numerik

# Data Preparation

## Mengatasi Missing Values
"""

# Handling missing value untuk kolom penting (textual/identitas):
df['authors'].fillna('Unknown Author', inplace=True)
df['categories'].fillna('Uncategorized', inplace=True)
df['description'].fillna('', inplace=True)

# Handling missing value pada kolom numerik:
df['average_rating'].fillna(df['average_rating'].median(), inplace=True)
df['num_pages'].fillna(df['num_pages'].median(), inplace=True)
df['ratings_count'].fillna(0, inplace=True)

# Untuk tahun terbit, jika ada:
if df['published_year'].isnull().sum() > 0:
    df = df[df['published_year'].notnull()]  # buang baris karena cukup penting untuk analisis tren

# menghapus sebanyak 4425 data pada fitur
df.dropna(subset=['subtitle'], inplace=True)

"""Insight:
* Mengatasi missing value menggunakan teknik imputasi menggunakan median pada fitur numerik, dikarenakan median adalah ukuran tendensi sentral yang robust (tahan) terhadap outlier. Sehingga, nilai-nilai ekstrem tidak mempengaruhinya secara signifikan.
* Pada fitur published_year missing value dihapus dikarenakan hanya 6 data yang hilang, sehingga dihapus saja karena tidak akan merubah distribusi data secara signifikan.
* Pada fitur kategorik, penanganan missing value dilakukan dengan teknik imputasi seperti menggunakan
"""

# Melihat kembali data setelah handling missing value
df.isnull().sum()

"""# Mengatasi Outliers"""

# Fungsi untuk mendeteksi outlier menggunakan metode IQR
def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    outliers = data[(data[column] < lower) | (data[column] > upper)]
    return outliers, lower, upper

df_capped = df.copy()

# Mendefinisikan visualisasi boxplot
numerical_cols_for_boxplot = ['average_rating', 'num_pages', 'ratings_count']

for col in numerical_cols_for_boxplot:
    _, lower, upper = detect_outliers_iqr(df_capped, col)
    df_capped[col] = np.where(df_capped[col] < lower, lower, df_capped[col])
    df_capped[col] = np.where(df_capped[col] > upper, upper, df_capped[col])

# Boxplot setelah capping (Membatasi Outlier ke Batas IQR))
# Update the subplot parameters to match the number of columns being plotted
plt.figure(figsize=(15, 5))
for i, col in enumerate(numerical_cols_for_boxplot):
    # Change 1, 3 to match the number of columns in numerical_cols_for_boxplot (which is 3)
    plt.subplot(1, 3, i+1)
    sns.boxplot(y=df_capped[col], color='lightblue')
    plt.title(f'Boxplot of {col} (Setelah Capping)')
plt.tight_layout()
plt.show()

print("Outlier ditangani dengan metode capping (Membatasi Outlier ke Batas IQR).")

"""Insight: sudah tidak terdapat outliers. outliers di-handling menggunakan teknik capping (membatasi outlier ke batas IQR)

## Text Preprocessing (untuk Content-Based Filtering)
"""

# Menggabungkan fitur
df_capped['combined_features'] = df['title'] + ' ' + df['authors'] + ' ' + df['categories'] + ' ' + df['description'] + ' ' + df['average_rating'].astype(str)

"""Insight: teks yang bersih membantu mempermudah dalam menganalisis kata, pembuatan fitur berbasis konten (TF-IDF), atau analisis sentimen."""

# Definisikan fungsi preprocessing teks
stemmer = PorterStemmer()

def preprocess_text(text):
    # Ubah ke huruf kecil
    text = text.lower()
    # Hapus tanda baca
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Hapus angka
    text = re.sub(r'\d+', '', text)
    # Tokenisasi
    tokens = nltk.word_tokenize(text)
    # Hapus stopwords dan lakukan stemming
    cleaned_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]
    # Gabungkan kembali
    return ' '.join(cleaned_tokens)

# preprocessing pada kolom 'description'
df_capped['description_clean'] = df_capped['description'].apply(preprocess_text)

# Contoh hasil cleaning
print("Contoh hasil pembersihan teks:")
print("\nDeskripsi asli:\n", df_capped['description'].iloc[0][:300])
print("\nDeskripsi setelah preprocessing:\n", df_capped['description_clean'].iloc[0][:300])

"""Insight: Setelah dibersihkan, teks deskripsi menjadi lebih ringkas dan berisi kata-kata kunci yang lebih relevan.

## Normalisasi/Standarisasi (untuk fitur numerik)
"""

scaler = MinMaxScaler()
df_capped[['average_rating', 'num_pages', 'ratings_count']] = scaler.fit_transform(df_capped[['average_rating', 'num_pages', 'ratings_count']])

# Cek distribusi rating setelah normalisasi
plt.figure(figsize=(6, 4))
sns.histplot(df_capped['average_rating'], bins=20, kde=True)
plt.title('Distribusi Normalized Rating')
plt.xlabel('Normalized Rating')
plt.ylabel('Jumlah Buku')
plt.show()

"""Insight:

Histogram di atas menunjukkan bahwa mayoritas buku menerima rating yang moderat hingga baik. Nilai rating yang terkonsentrasi di sekitar 0.55-0.65 menunjukkan bahwa sebagian besar buku tidak mendapatkan rating yang ekstrem (sangat rendah atau sangat tinggi).
Ada sebagian kecil buku dengan rating sangat rendah dan sangat tinggi. Ini menunjukkan bahwa meskipun sebagian besar rating cenderung di tengah, ada juga beberapa kasus buku yang sangat tidak disukai atau sangat disukai.
Distribusi yang cenderung normal seringkali diharapkan dalam data rating yang dikumpulkan dari banyak pengguna, karena efek "rata-rata" dari banyak opini.
Singkatnya, grafik ini secara visual menunjukkan sebaran atau frekuensi kemunculan nilai rating buku yang sudah dinormalisasi, menunjukkan bahwa sebagian besar rating terkonsentrasi di sekitar nilai tengah (median).

# Membangun Model Rekomendasi

## Collaborative Filtering

### Matriks Interaksi (untuk Collaborative Filtering)
"""

# Simulasi user_id
np.random.seed(42)
num_users = 5000
df_capped['user_id'] = np.random.choice([f'user_{i}' for i in range(1, num_users+1)], size=len(df_capped))

# Pastikan rating berupa float (jika belum)
df_capped['average_rating'] = pd.to_numeric(df_capped['average_rating'], errors='coerce')

"""Insight:
* Karena dataset belum memiliki kolom user_id, kode ini mensimulasikan data pengguna sebanyak 5.000 user yang akan digunakan untuk membentuk user-item interaction matrix dalam collaborative filtering.
* langkah ini penting dilakukan sebelum melakukan analisis atau modeling (seperti prediksi rating, filtering item dengan rating tinggi).
"""

# User-Item Matrix: baris = user, kolom = buku (isbn13), isi = rating
user_item_matrix = df_capped.pivot_table(index='user_id', columns='isbn13', values='average_rating')

print("Ukuran User-Item Matrix:", user_item_matrix.shape)
user_item_matrix.head()

"""Insight:
* Membuat user-item interaction matrix, yaitu bentuk data yang umum digunakan untuk Collaborative Filtering.
* terlihat dari table yang ditampilkan bahwa sebagian besar nilai di matriks ini adalah NaN, hal itu karena tidak semua user memberi rating ke semua buku. Ini menunjukkan seberapa sparse (jarang diisi) dari matriks interaksi, yang merupakan ciri umum dalam sistem rekomendasi.

* Cosine Similarity untuk Collaborative Filtering (Item-Based)
"""

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.impute import SimpleImputer

# Cosine similarity antara item (berdasarkan user rating)
imputer = SimpleImputer(strategy='constant', fill_value=0)
item_matrix = imputer.fit_transform(user_item_matrix.T)

# Rename the similarity matrix for Collaborative Filtering
similarity_matrix = cosine_similarity(item_matrix)

"""Insight:
* Data dipersiapkan agar dapat dihitung kesamaan antar item berdasarkan vektor rating dari para user.
* dikarenakan besar matrik bernilai NaN, maka NaN diganti dengan 0 sebagai pendekatan untuk membangun item-based recommender menggunakan similarity.
"""

# Store the ISBNs corresponding to the columns
book_isbns = user_item_matrix.columns

# Prediksi rating: dot product dari similarity matrix dan user-item matrix
# Use the Collaborative Filtering similarity matrix for prediction
pred_ratings = user_item_matrix.fillna(0).dot(similarity_matrix) / np.array([np.abs(similarity_matrix).sum(axis=1)])

# Hasilnya adalah prediksi rating untuk semua user dan buku
print("Prediksi rating shape:", pred_ratings.shape)

"""Insight:
* Ini merupakan implementasi sederhana dari item-based collaborative filtering berbasis similarity antar item.
* Menghasilkan prediksi rating dari user terhadap item yang belum pernah mereka rating, berdasarkan kemiripan item.
* Matriks berukuran (jumlah_user, jumlah_item) yang berisi nilai prediksi rating, siap digunakan untuk menyusun rekomendasi personal
"""

def recommend_books(isbn, top_n=5):
    if isbn not in user_item_matrix.columns:
        return f"Buku dengan ISBN {isbn} tidak ditemukan."

    isbn_index = user_item_matrix.columns.get_loc(isbn)

    sim_scores = list(enumerate(similarity_matrix[isbn_index]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]

    # Ambil indeks buku yang direkomendasikan dalam user_item_matrix columns
    recommended_indices = [i[0] for i in sim_scores]

    # Ambil ISBNs dari buku-buku yang direkomendasikan
    recommended_isbns = user_item_matrix.columns[recommended_indices]

    # Ambil informasi buku-buku yang direkomendasikan dari df_capped
    recommended_books = df_capped[df_capped['isbn13'].isin(recommended_isbns)].drop_duplicates(subset=['isbn13'])

    return recommended_books[['title', 'authors', 'average_rating']]

# Ganti dengan ISBN yang valid di dataset
isbn_sample = df_capped['isbn13'].iloc[0]
print("Rekomendasi buku mirip dengan:", df_capped[df_capped['isbn13'] == isbn_sample]['title'].values[0])
recommend_books(isbn_sample, top_n=5)

def recommend_books_by_title(title_input, top_n=5):
    title_input = title_input.lower()

    # Cari judul buku yang cocok atau paling mendekati
    matched_books = df_capped[df_capped['title'].str.lower().str.contains(title_input, na=False)]

    if matched_books.empty:
        return f"Buku dengan judul mengandung '{title_input}' tidak ditemukan."

    # Ambil ISBN dari buku pertama yang cocok
    matched_book = matched_books.iloc[0]
    matched_title = matched_book['title']
    matched_isbn = matched_book['isbn13']

    # Tampilkan info buku input
    print(f"Menampilkan rekomendasi mirip dengan:\n→ Judul: {matched_title}\n→ ISBN: {matched_isbn}")

    if matched_isbn not in user_item_matrix.columns:
         return f"ISBN {matched_isbn} tidak ditemukan dalam matriks rekomendasi."

    matched_isbn_index_in_matrix = user_item_matrix.columns.get_loc(matched_isbn)

    similar_scores = cf_similarity_matrix[matched_isbn_index_in_matrix]

    similar_scores_series = pd.Series(similar_scores, index=user_item_matrix.columns)

    top_similar = similar_scores_series.sort_values(ascending=False).iloc[1:top_n+1]

    # Ambil informasi buku-buku yang direkomendasikan
    recommended_books = df_capped[df_capped['isbn13'].isin(top_similar.index)][['title', 'authors', 'average_rating']].drop_duplicates()
    return recommended_books

# Test the recommendation system
book_name_input = input('Masukkan judul buku favoritmu: ')
recommend_books_by_title(book_name_input)

"""Insight:
* Fungsi di atas menunjukkan bahwa sistem dapat menerima input berupa sebagian judul buku dari pengguna, lalu memberikan daftar rekomendasi buku lain yang mirip berdasarkan kemiripan konten (item-item similarity). Dalam hal ini, kemiripan dihitung berdasarkan pola rating pengguna sebelumnya (menggunakan item-based collaborative filtering).
* Output di atas adalah judul buku yang diketik pengguna (misalnya: 'I'm Telling You Stories') yang dijadikan referensi untuk menelusuri buku-buku lain yang memiliki pola rating serupa dari para pembaca.

## Content Based Filtering

* Fungsi TF-IDF dan Cosine Similarity untuk algoritma CBF
"""

# Vectorizer untuk deskripsi buku
tfidf = TfidfVectorizer(stop_words='english')
# Pastikan tidak ada nilai NaN di kolom deskripsi
df_capped['description'] = df_capped['description'].fillna('')
# Bentuk matriks TF-IDF
tfidf_matrix = tfidf.fit_transform(df_capped['description'])

# Hitung similarity antar semua buku berdasarkan deskripsi
similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Fungsi rekomendasi berdasarkan konten
def recommend_books(title_input, top_n=5):
    all_titles = df_capped['title'].tolist()
    close_matches = difflib.get_close_matches(title_input, all_titles, n=1, cutoff=0.6)

    if not close_matches:
        return f"Tidak ditemukan buku dengan judul mendekati '{title_input}'."

    matched_title = close_matches[0]
    print(f"Mencari berdasarkan judul terdekat: '{matched_title}'")

    matched_book_row = df_capped[df_capped['title'] == matched_title]

    if matched_book_row.empty:
        return f"Judul '{matched_title}' ditemukan di katalog asli, tetapi tidak ada di dataframe setelah pembersihan (df_capped)."

    idx_in_capped = matched_book_row.index[0]
    idx = df_capped.reset_index().index[df_capped.reset_index()['index'] == idx_in_capped].values[0]


    # Ambil skor similarity dengan semua buku lain
    sim_scores = list(enumerate(similarity_matrix[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]

    # Ambil indeks buku yang direkomendasikan
    book_indices_positional = [i[0] for i in sim_scores]

    recommended_books = df_capped.iloc[book_indices_positional].drop_duplicates(subset=['isbn13'])

    return recommended_books[['title', 'authors', 'description']]

# Testing
book_name_input = input('Masukkan judul buku favoritmu: ')
recommend_books(book_name_input)

"""Insight:
* Kode di atas berhasil merekomendasikan buku-buku yang memiliki kemiripan secara isi (konten) dengan buku yang dicari oleh pengguna berdasarkan deskripsinya. Sistem ini tidak memerlukan data dari pengguna lain, melainkan fokus pada informasi intrinsik dari buku seperti deskripsi (description), dan menggunakan matriks kesamaan (similarity matrix) yang dibentuk dari deskripsi melalui teknik seperti TF-IDF dan cosine similarity.
* Berdasarkan contoh input **“I'm Telling You Stories”**, sistem berhasil mencocokkan judul terdekat dan kemudian mengembalikan daftar buku yang memiliki topik serupa atau gaya penulisan sejenis, yaitu kumpulan esai, cerita filosofis, atau literatur reflektif. Hal ini menunjukkan bahwa sistem cukup efektif dalam menangkap nuansa tema atau gaya konten dari buku input dan mencari padanannya di koleksi yang ada.

# Evaluasi

### Fungsi Metrik Evaluasi
"""

def precision_at_k(recommended_items, relevant_items, k):
    recommended_at_k = recommended_items[:k]
    relevant_count = len(set(recommended_at_k) & set(relevant_items))
    return relevant_count / k

def recall_at_k(recommended_items, relevant_items, k):
    if len(relevant_items) == 0:
        return 0.0
    recommended_at_k = recommended_items[:k]
    relevant_count = len(set(recommended_at_k) & set(relevant_items))
    return relevant_count / len(relevant_items)

def reciprocal_rank(recommended_items, relevant_items):
    for rank, item in enumerate(recommended_items, start=1):
        if item in relevant_items:
            return 1 / rank
    return 0.0

def coverage(all_recommendations, total_items):
    unique_recommended = set(item for user_rec in all_recommendations.values() for item in user_rec)
    return len(unique_recommended) / total_items

def precision_at_k(recommended_items, relevant_items, k):
    recommended_at_k = recommended_items[:k]
    relevant_count = len(set(recommended_at_k) & set(relevant_items))
    return relevant_count / k if k > 0 else 0.0

def recall_at_k(recommended_items, relevant_items, k):
    if len(relevant_items) == 0:
        return 0.0
    recommended_at_k = recommended_items[:k]
    relevant_count = len(set(recommended_at_k) & set(relevant_items))
    return relevant_count / len(relevant_items)

def f1_score_at_k(recommended_items, relevant_items, k):
    p = precision_at_k(recommended_items, relevant_items, k)
    r = recall_at_k(recommended_items, relevant_items, k)
    if (p + r) == 0:
        return 0.0
    return (2 * p * r) / (p + r)

def reciprocal_rank(recommended_items, relevant_items):
    for rank, item in enumerate(recommended_items, start=1):
        if item in relevant_items:
            return 1 / rank
    return 0.0

def hit_rate_at_k(recommended_items, relevant_items, k):
    recommended_at_k = recommended_items[:k]
    # Cek apakah ada irisan antara item yang direkomendasikan dan item yang relevan
    if len(set(recommended_at_k) & set(relevant_items)) > 0:
        return 1.0
    return 0.0

def coverage(all_recommendations_list, total_items_count):
    unique_recommended = set(all_recommendations_list)
    return len(unique_recommended) / total_items_count if total_items_count > 0 else 0.0

"""#### Fungsi Metrik Evaluasi Collaborative Filtering"""

def evaluate_collaborative(user_item_matrix, pred_ratings, top_k=5):
    precision_list, recall_list, f1_list, mrr_list, hit_list = [], [], [], [], []
    all_recommended_ids_for_coverage = []
    total_items = user_item_matrix.shape[1]

    if isinstance(pred_ratings, pd.DataFrame):
        pred_ratings_values = pred_ratings.values
    else:
        pred_ratings_values = pred_ratings

    for idx, (user_id_label, true_ratings_series) in tqdm(enumerate(user_item_matrix.iterrows()),
                                                           total=len(user_item_matrix),
                                                           desc="Evaluating CF"):
        true_ratings = true_ratings_series.values
        predicted = pred_ratings_values[idx]

        relevant_indices = np.where(true_ratings >= 0.8)[0]
        # Mengubah indeks relevan menjadi ID buku yang sebenarnya (nama kolom)
        relevant_book_ids = list(user_item_matrix.columns[relevant_indices])

        # Urutkan buku berdasarkan prediksi rating tertinggi
        # Ambil indeks kolom dari rating yang diprediksi
        recommended_indices = np.argsort(predicted)[::-1]
        # Ubah indeks menjadi ID buku yang sebenarnya (nama kolom)
        recommended_book_ids = list(user_item_matrix.columns[recommended_indices])

        # Ambil top_k rekomendasi
        recommended_at_k = recommended_book_ids[:top_k]

        # Hitung metrik untuk iterasi saat ini
        p_at_k = precision_at_k(recommended_at_k, relevant_book_ids, top_k)
        r_at_k = recall_at_k(recommended_at_k, relevant_book_ids, top_k)
        f1_at_k = f1_score_at_k(recommended_at_k, relevant_book_ids, top_k)
        rr = reciprocal_rank(recommended_book_ids, relevant_book_ids)
        hr_at_k = hit_rate_at_k(recommended_at_k, relevant_book_ids, top_k)

        # Tambahkan ke daftar
        precision_list.append(p_at_k)
        recall_list.append(r_at_k)
        f1_list.append(f1_at_k)
        mrr_list.append(rr)
        hit_list.append(hr_at_k)
        all_recommended_ids_for_coverage.extend(recommended_at_k)

    # Hitung rata-rata semua metrik
    avg_precision = np.mean(precision_list) if precision_list else 0.0
    avg_recall = np.mean(recall_list) if recall_list else 0.0
    avg_f1_score = np.mean(f1_list) if f1_list else 0.0
    avg_mrr = np.mean(mrr_list) if mrr_list else 0.0
    avg_hit_rate = np.mean(hit_list) if hit_list else 0.0

    # Coverage menggunakan total item dari user_item_matrix
    final_coverage = coverage(all_recommended_ids_for_coverage, total_items)


    print("\n--- Collaborative Filtering Evaluation Results ---")
    print(f"Precision@{top_k}: {avg_precision:.4f}")
    print(f"Recall@{top_k}: {avg_recall:.4f}")
    print(f"F1-Score@{top_k}: {avg_f1_score:.4f}")
    print(f"MRR: {avg_mrr:.4f}")
    print(f"Hit Rate@{top_k}: {avg_hit_rate:.4f}")
    print(f"Coverage: {final_coverage:.4f}")

# Collaborative (misalnya dengan matrix factorization atau SVD)
evaluate_collaborative(user_item_matrix, pred_ratings, top_k=5)

"""#### Fungsi Metrik Evaluasi Content-Based Filtering"""

def evaluate_content_based(df_capped, similarity, top_k=5):
    precision_list, recall_list, f1_list, mrr_list, hit_list = [], [], [], [], []
    all_recommended_ids_for_coverage = []
    df_reset =df_capped.reset_index(drop=True)
    total_items = len(df_reset)

    for current_idx, row in tqdm(df_reset.iterrows(), total=len(df_reset), desc="Evaluating CBF"):
        sim_scores = list(enumerate(similarity[current_idx]))

        # Urutkan buku berdasarkan skor kesamaan (tertinggi ke terendah)
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_k+1]

        # Ambil ID buku yang direkomendasikan
        recommended_ids = [i[0] for i in sim_scores]
        relevant_ids = [current_idx]

        # Hitung metrik untuk iterasi saat ini
        p_at_k = precision_at_k(recommended_ids, relevant_ids, top_k)
        r_at_k = recall_at_k(recommended_ids, relevant_ids, top_k)
        f1_at_k = f1_score_at_k(recommended_ids, relevant_ids, top_k)
        rr = reciprocal_rank(recommended_ids, relevant_ids)
        hr_at_k = hit_rate_at_k(recommended_ids, relevant_ids, top_k)

        # Tambahkan ke daftar
        precision_list.append(p_at_k)
        recall_list.append(r_at_k)
        f1_list.append(f1_at_k)
        mrr_list.append(rr)
        hit_list.append(hr_at_k)
        all_recommended_ids_for_coverage.extend(recommended_ids)

    # Hitung rata-rata semua metrik
    avg_precision = np.mean(precision_list)
    avg_recall = np.mean(recall_list)
    avg_f1_score = np.mean(f1_list)
    avg_mrr = np.mean(mrr_list)
    avg_hit_rate = np.mean(hit_list)
    # total_unique_books_in_catalog should be the total number of items in the matrix
    total_unique_books_in_catalog = similarity.shape[0]
    final_coverage = coverage(all_recommended_ids_for_coverage, total_unique_books_in_catalog)


    print("\n--- Content-Based Filtering Evaluation Results ---")
    print(f"Precision@{top_k}: {avg_precision:.4f}")
    print(f"Recall@{top_k}: {avg_recall:.4f}")
    print(f"F1-Score@{top_k}: {avg_f1_score:.4f}") # Metrik baru
    print(f"MRR: {avg_mrr:.4f}")
    print(f"Hit Rate@{top_k}: {avg_hit_rate:.4f}") # Metrik baru
    print(f"Coverage: {final_coverage:.4f}")

# Evaluasi CBF
evaluate_content_based(df_capped, similarity_matrix, top_k=5)

"""## Analisis Komparatif pada Metrik Evaluasi

Dari hasil evaluasi di atas, terlihat perbedaan kinerja yang sangat signifikan antara kedua pendekatan, mari kita bahas lebih detail dengan mengaitkannya dengan problem statement (PS) dan goals dalam proyek ini:

**1. Relevansi dan Personalisasi (Menjawab PS1 & Goal 2):**
* Content-Based Filtering (CBF) menunjukkan performa lebih baik dibandingkan Collaborative Filtering (CF) dalam hal relevansi rekomendasi, meskipun keduanya masih memiliki performa yang rendah secara absolut.
* Dengan Precision@5 sebesar 0.0013, CBF setidaknya menunjukkan adanya peluang kecil untuk menghasilkan rekomendasi yang relevan, dibandingkan CF yang Precision@5-nya adalah 0.0000, yang berarti tidak ada dari 5 rekomendasi yang berhasil relevan untuk pengguna.
* Recall@5 CBF (0.0067) juga masih lebih tinggi dari CF (0.0000), menunjukkan bahwa hanya CBF yang mampu menjangkau sebagian kecil dari item yang relevan untuk pengguna.
* Demikian pula, F1-Score@5 CBF (0.0022) menunjukkan ada sedikit keseimbangan antara presisi dan cakupan, sedangkan CF gagal menunjukkan performa apapun di aspek ini (F1-Score@5 = 0.0000).

**2. Efisiensi Penemuan Buku (Menjawab PS2 & Goal 2):**
* MRR (Mean Reciprocal Rank) pada CF hanya 0.0012, sangat rendah dibandingkan CBF yang mencapai 0.0060. Artinya, bila pengguna menemukan rekomendasi yang relevan, model CBF cenderung menempatkannya pada posisi yang lebih tinggi dibanding CF.
* Hit Rate@5 untuk CF adalah 0.0000, menunjukkan bahwa tidak ada pengguna yang menerima satu pun rekomendasi relevan di 5 teratas. Sebaliknya, meskipun rendah, CBF memiliki Hit Rate@5 sebesar 0.0067, yang menunjukkan keberhasilan terbatas dalam memberikan satu item relevan dalam 5 teratas.

**3. Potensi Retensi dan Kepuasan Pengguna (Menjawab PS3 & Goal 3):**
* Secara keseluruhan, CBF menunjukkan potensi awal dalam menghasilkan rekomendasi yang relevan meskipun masih sangat terbatas.
* Dengan performa CF yang nol pada hampir seluruh metrik relevansi utama, hal ini dapat mengganggu pengalaman pengguna karena mereka tidak mendapatkan rekomendasi yang bermanfaat atau menarik.
* CBF, walau performanya rendah, masih dapat menjadi pondasi awal untuk meningkatkan kepuasan pengguna melalui pengembangan lebih lanjut atau penggabungan dengan pendekatan lain (misalnya: hybrid).

**4. Cakupan Rekomendasi:**
* Coverage adalah satu-satunya metrik di mana CBF secara signifikan unggul, dengan skor 0.8878 dibandingkan CF yang hanya 0.0143. Ini berarti CBF dapat menjangkau hampir 89% dari total item dalam katalog, dibandingkan dengan CF yang sangat terbatas hanya mampu merekomendasikan sekitar 1.4% item.
* Tingginya coverage pada CBF menjadi nilai tambah untuk mengatasi masalah cold start, terutama pada buku-buku baru atau niche, di mana interaksi pengguna belum tersedia.

**Kesimpulan Hasil Proyek**:
Berdasarkan hasil evaluasi, **Content-Based Filtering (CBF)** meskipun memiliki performa prediktif yang masih rendah, terbukti lebih baik dibandingkan Collaborative Filtering (CF) dalam menghasilkan rekomendasi yang sedikit lebih relevan, terjangkau, dan mencakup lebih banyak item dari katalog.

**Collaborative Filtering**, di sisi lain, menunjukkan performa yang sangat lemah di semua metrik relevansi dan penemuan, sehingga belum layak digunakan dalam bentuk saat ini.
"""